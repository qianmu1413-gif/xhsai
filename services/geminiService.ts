
import { FidelityMode, PersonaAnalysis, BulkNote, AttachedFile } from "../types";
import { configRepo } from "./repository";
import { ANALYSIS_SYSTEM_PROMPT } from "../constants";
import mammoth from "mammoth"; // Correctly import mammoth from the module map

// åè®®åˆ†éš”ç¬¦
const DATA_MARKER = "###MATRIX_DATA_START###";
const THOUGHT_START = "[[THOUGHT]]";
const THOUGHT_END = "[[/THOUGHT]]";

const cleanMarkdown = (text: string): string => {
    if (!text) return "";
    return text
        .replace(/\*\*/g, "")
        .replace(/\*/g, "")
        .replace(/`/g, "")
        .replace(/^#+\s*/gm, "")
        .trim();
};

const extractAndParseJSON = (text: string): any => {
    if (!text) return null;
    let json: any = null;
    try { json = JSON.parse(text); } catch (e) {}
    if (!json) {
        let cleanText = text.replace(/```json/gi, '').replace(/```/g, '').trim();
        try { json = JSON.parse(cleanText); } catch (e) {}
    }
    if (!json) {
        const match = text.match(/\{[\s\S]*\}/);
        if (match) {
            try { json = JSON.parse(match[0]); } catch (e) {}
        }
    }
    if (json) {
        if (json.tone) json.tone = cleanMarkdown(json.tone);
        if (json.structure) json.structure = cleanMarkdown(json.structure);
        if (json.emojiDensity) json.emojiDensity = cleanMarkdown(json.emojiDensity);
    }
    return json;
};

// --- FILE PROCESSING HELPERS ---

const fetchUrlAsBlob = async (url: string): Promise<Blob> => {
    try {
        // 1. Try direct fetch
        const response = await fetch(url);
        if (!response.ok) throw new Error(`Direct fetch failed: ${response.statusText}`);
        return await response.blob();
    } catch (e: any) {
        // 2. Fallback to CORS proxy if direct fetch fails (common with COS/S3)
        console.warn("Direct fetch failed, trying proxy...", e);
        try {
            const proxyUrl = `https://corsproxy.io/?${encodeURIComponent(url)}`;
            const response = await fetch(proxyUrl);
            if (!response.ok) throw new Error(`Proxy fetch failed: ${response.statusText}`);
            return await response.blob();
        } catch (proxyErr: any) {
            console.error("Fetch Blob Error:", proxyErr);
            throw new Error(`æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹ (CORS/Network): ${url}`);
        }
    }
};

const blobToBase64 = (blob: Blob): Promise<string> => {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => {
            const res = reader.result as string;
            // Remove Data URI prefix (e.g. "data:application/pdf;base64,")
            const base64 = res.split(',')[1];
            resolve(base64);
        };
        reader.onerror = reject;
        reader.readAsDataURL(blob);
    });
};

const extractDocxText = async (blob: Blob): Promise<string> => {
    const arrayBuffer = await blob.arrayBuffer();
    if (mammoth) {
        try {
            const result = await mammoth.extractRawText({ arrayBuffer: arrayBuffer });
            return result.value;
        } catch (e) {
            console.error("Mammoth Extract Error", e);
            return "[Error extracting text from DOCX - File might be corrupted]";
        }
    }
    return "[System: Document parser not loaded. Please refresh]";
};

const prepareFilePart = async (file: AttachedFile): Promise<any> => {
    try {
        let mimeType = file.mimeType || 'text/plain';
        let blob: Blob | null = null;
        
        // ğŸ”´ PRIORITY 1: Read directly from local file object if available
        // This completely bypasses CORS issues for newly uploaded files
        if (file.file) {
            blob = file.file;
            mimeType = file.file.type || mimeType;
        } 
        // Priority 2: Fetch from URL
        else if (file.isUrl || file.data.startsWith('http')) {
             blob = await fetchUrlAsBlob(file.data);
             if (blob.type) mimeType = blob.type;
        } 
        // Priority 3: Base64 Data URI
        else if (file.data.startsWith('data:')) {
             const res = await fetch(file.data);
             blob = await res.blob();
        }

        if (!blob) {
            return { text: `[File: ${file.name} - Format unknown]` };
        }

        // 2. Process based on Type
        // Gemini supports PDF and Image via inlineData
        if (mimeType.includes('pdf')) {
            const base64Data = await blobToBase64(blob);
            return { inlineData: { mimeType: 'application/pdf', data: base64Data } };
        } 
        else if (mimeType.startsWith('image/')) {
            const base64Data = await blobToBase64(blob);
            return { inlineData: { mimeType: mimeType, data: base64Data } };
        }
        // For Office docs (DOCX) -> Extract Text
        else if (mimeType.includes('wordprocessingml') || file.name.endsWith('.docx')) {
            const textContent = await extractDocxText(blob);
            return { text: `[æ–‡æ¡£å†…å®¹ ${file.name}]:\n${textContent}` };
        }
        // For Text based files
        else if (mimeType.startsWith('text/') || file.name.endsWith('.txt') || file.name.endsWith('.md')) {
            const textContent = await blob.text();
            return { text: `[æ–‡æ¡£å†…å®¹ ${file.name}]:\n${textContent}` };
        }
        else {
             return { text: `[æ–‡ä»¶ ${file.name} (${mimeType}) - æš‚ä¸æ”¯æŒæ·±åº¦å†…å®¹åˆ†æï¼Œä»…ä½œä¸ºä¸Šä¸‹æ–‡å‚è€ƒ]` };
        }

    } catch (e: any) {
        console.error("File Prep Error", e);
        return { text: `[æ–‡ä»¶è¯»å–å¤±è´¥: ${file.name} - ${e.message}]` };
    }
};

// --- API CALLER ---

const fetchGemini = async (endpoint: string, googleBody: any, stream: boolean = false) => {
  const sysConfig = await configRepo.getSystemConfig();
  const { apiKey, baseUrl, model } = sysConfig.gemini;
  
  if (!apiKey) throw new Error("AI å¯†é’¥æœªé…ç½®ï¼Œè¯·è”ç³»ç®¡ç†å‘˜");

  const isOpenAI = apiKey.startsWith('sk-') || baseUrl.includes('vectorengine') || baseUrl.includes('openai');

  if (isOpenAI) {
      // OpenAI Compatibility Mode (Simplified)
      let targetUrl = baseUrl.replace(/\/$/, '');
      if (!targetUrl.endsWith('/v1/chat/completions')) {
          if (targetUrl.endsWith('/v1')) targetUrl += '/chat/completions';
          else targetUrl += '/v1/chat/completions';
      }

      const messages: any[] = [];
      if (googleBody.systemInstruction) {
          messages.push({ role: 'system', content: googleBody.systemInstruction.parts[0].text });
      }
      if (googleBody.contents) {
          for (const c of googleBody.contents) {
              const contentParts: any[] = [];
              if (c.parts) {
                  for (const p of c.parts) {
                      if (p.text) {
                          contentParts.push({ type: 'text', text: p.text });
                      } else if (p.inlineData) {
                          contentParts.push({ 
                              type: 'image_url', 
                              image_url: { url: `data:${p.inlineData.mimeType};base64,${p.inlineData.data}` } 
                          });
                      }
                  }
              }
              const finalContent = (contentParts.length === 1 && contentParts[0].type === 'text') ? contentParts[0].text : contentParts;
              messages.push({ role: c.role || 'user', content: finalContent });
          }
      }

      const openAIBody = {
          model: model,
          messages: messages,
          stream: stream,
          temperature: googleBody.generationConfig?.temperature || 0.7,
          max_tokens: googleBody.generationConfig?.maxOutputTokens || 4096
      };

      const response = await fetch(targetUrl, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${apiKey}` },
          body: JSON.stringify(openAIBody)
      });

      if (!response.ok) throw new Error(`API Error: ${response.status}`);
      return response;

  } else {
      // Native Google Gemini API
      let finalUrl = "";
      const cleanBaseUrl = baseUrl.replace(/\/$/, '');
      if (cleanBaseUrl.includes('/models/')) {
          const separator = endpoint.includes('?') ? '&' : '?';
          finalUrl = `${cleanBaseUrl}${separator}key=${apiKey}`;
      } else {
          const separator = endpoint.includes('?') ? '&' : '?';
          finalUrl = `${cleanBaseUrl}/v1beta/models/${model}:${endpoint}${separator}key=${apiKey}`;
      }

      const response = await fetch(finalUrl, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify(googleBody)
      });

      if (!response.ok) throw new Error(`Google API Error: ${response.status}`);
      return response;
  }
};

// --- EXPORTED FUNCTIONS ---

export const analyzeMaterials = async (files: AttachedFile[]): Promise<string> => {
    if (files.length === 0) return "æ²¡æœ‰æ£€æµ‹åˆ°å¯åˆ†æçš„æ–‡ä»¶ã€‚";

    // 1. Prepare parts with REAL content (base64 images/pdf, extracted text)
    // Map promises first to run in parallel
    const fileParts = await Promise.all(files.map(f => prepareFilePart(f)));

    const promptPart = { text: `ä½ æ˜¯ä¸€ä½é¡¶çº§å†…å®¹ç­–ç•¥ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹ ${files.length} ä»½ç´ æè¿›è¡Œã€æ·±åº¦æ‹†è§£ã€‘ï¼Œç›®çš„æ˜¯ä¸ºäº†è¾…åŠ©æ’°å†™æœ€å…·è½¬åŒ–ç‡çš„å°çº¢ä¹¦ç¬”è®°ã€‚

è¯·ä¸è¦åªåšç®€å•çš„æ‘˜è¦ï¼Œæˆ‘è¦çš„æ˜¯ã€è¥é”€çˆ†ç‚¹ã€‘å’Œã€å†™ä½œç´ æã€‘ã€‚
å¯¹äºå›¾ç‰‡ï¼Œè¯·åˆ†æå…¶è§†è§‰é£æ ¼ã€å…³é”®å…ƒç´ å’Œä¼ è¾¾çš„æƒ…ç»ªã€‚
å¯¹äºæ–‡æ¡£ï¼ˆPDF/Wordï¼‰ï¼Œè¯·æå–æ ¸å¿ƒå¹²è´§ã€æ•°æ®å’Œä¸“ä¸šèƒŒä¹¦ã€‚

è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºåˆ†ææŠ¥å‘Šï¼ˆMarkdownï¼‰ï¼š

## 1. æ ¸å¿ƒå–ç‚¹æç‚¼ (Unique Selling Points)
*è¯·åˆ—å‡º3-5ä¸ªæœ€å¼ºçš„äº§å“/å†…å®¹ä¼˜åŠ¿ï¼Œç”¨â€œç—›ç‚¹-è§£å†³æ–¹æ¡ˆâ€çš„é€»è¾‘æè¿°ã€‚*
- **[å–ç‚¹1]**: é’ˆå¯¹ [ä»€ä¹ˆç—›ç‚¹]ï¼Œæä¾›äº† [ä»€ä¹ˆè§£å†³]ï¼Œä¼˜åŠ¿æ˜¯ [å…·ä½“å‚æ•°/æˆåˆ†/æ•ˆæœ]ã€‚
- **[å–ç‚¹2]**: ...

## 2. ç›®æ ‡äººç¾¤ç”»åƒ (Target Audience)
*è°æœ€éœ€è¦è¿™ä¸ªï¼Ÿ*

## 3. å†…å®¹ç»†èŠ‚ç´ æåº“ (Content Details)
*æå–å…·ä½“çš„ã€å¯ç›´æ¥ç”¨äºæ­£æ–‡çš„æ•°æ®ã€é‡‘å¥æˆ–åœºæ™¯æè¿°ã€‚*
- **å…³é”®æ•°æ®**: (ä»·æ ¼ã€å«é‡ã€å®éªŒæ•°æ®ç­‰)
- **è§†è§‰/åœºæ™¯**: (å›¾ç‰‡ä¸­çš„æ°›å›´ã€é¢œè‰²ã€é€‚ç”¨åœºæ™¯)

## 4. çˆ†æ¬¾é€‰é¢˜åˆ‡å…¥ç‚¹
*åŸºäºç´ æï¼Œç»™å‡º 3 ä¸ªé«˜æµé‡çš„ç¬”è®°æ ‡é¢˜åˆ‡å…¥æ–¹å‘ã€‚*

---
ä»¥ä¸‹æ˜¯ç´ æå†…å®¹ï¼š` };

    const parts = [promptPart, ...fileParts];

    try {
        const response = await fetchGemini('generateContent', {
            contents: [{ role: 'user', parts: parts }],
            generationConfig: { temperature: 0.3, maxOutputTokens: 8192 }
        });
        
        const data = await response.json();
        const text = data.candidates?.[0]?.content?.parts?.[0]?.text;
        return text || "æœªèƒ½ç”Ÿæˆåˆ†æç»“æœã€‚";
    } catch (e: any) {
        throw new Error(`èµ„æ–™åˆ†æå¤±è´¥: ${e.message}`);
    }
};

export const streamExpertGeneration = async (
  context: string,
  files: AttachedFile[],
  personaPrompt: string,
  fidelity: FidelityMode,
  count: number = 1,
  wordCountLimit: number = 400,
  onToken?: (text: string, thought: string) => void
): Promise<{ dialogueText: string; thought: string; notes: BulkNote[] }> => {

  let modeInstruction = fidelity === FidelityMode.STRICT ? 
    `ã€ä¸“ä¸š/ä¸¥è°¨æ¨¡å¼ã€‘ç»å¯¹å¿ å®äºå‚è€ƒèµ„æ–™ï¼Œç¦æ­¢è™šæ„ã€‚` : 
    `ã€åˆ›æ„/ç´ äººæ¨¡å¼ã€‘å‘æŒ¥åˆ›æ„ï¼Œåˆç†è”æƒ³ï¼Œæƒ…æ„Ÿæ¸²æŸ“ï¼Œå£è¯­åŒ–è¡¨è¾¾ã€‚`;

  const systemInstruction = {
    parts: [{ text: `ä½ æ˜¯ä¸€ä½é¡¶çº§å°çº¢ä¹¦å†…å®¹ä¸“å®¶ã€‚
åšä¸»é£æ ¼è®¾å®šï¼š${personaPrompt}
${modeInstruction}

ã€ç»å¯¹è§„åˆ™ - å¿…é¡»éµå®ˆã€‘
1. è¯­è¨€ï¼šç®€ä½“ä¸­æ–‡ã€‚
2. **å­—æ•°çº¢çº¿**ï¼šæ¯ç¯‡ç¬”è®°æ­£æ–‡ä¸¥æ ¼æ§åˆ¶åœ¨ **${wordCountLimit} å­—ä»¥å†…**ï¼
3. **æ ‡é¢˜é™åˆ¶**ï¼šæ ‡é¢˜å¿…é¡» **<= 20 å­—**ã€‚ä¸è¦ä½¿ç”¨è¿‡é•¿çš„æ ‡é¢˜ã€‚
4. **å¤‡é€‰æ ‡é¢˜**ï¼šåœ¨ [[THOUGHT]] å—ä¹‹åï¼Œæ­£å¼è¾“å‡ºæ­£æ–‡ä¹‹å‰ï¼Œè¯·ä¸“é—¨è¾“å‡ºä¸€ä¸ªæ®µè½ï¼Œåˆ—å‡º **5ä¸ª** ä¸åŒè§’åº¦çš„çˆ†æ¬¾å¤‡é€‰æ ‡é¢˜ï¼Œæ¯ä¸ªæ ‡é¢˜éƒ½å¿…é¡» <= 20å­—ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
   **ã€å¤‡é€‰æ ‡é¢˜ã€‘**
   1. ...
   2. ...
   3. ...
   4. ...
   5. ...

5. æµç¨‹ï¼š
   - å…ˆè¾“å‡ºæ€è€ƒè¿‡ç¨‹ [[THOUGHT]]...[[/THOUGHT]]
   - è¾“å‡º **ã€å¤‡é€‰æ ‡é¢˜ã€‘** åˆ—è¡¨
   - å†è¾“å‡ºæ­£æ–‡ (è¯·æŒ‘é€‰ä¸€ä¸ªæœ€å¥½çš„æ ‡é¢˜ä½œä¸ºæ­£æ–‡ç¬¬ä¸€è¡Œï¼Œçº¯æ–‡æœ¬)
   - æœ€åè¾“å‡ºæ•°æ®åˆ†éš”ç¬¦ ${DATA_MARKER} å’Œ JSONæ•°æ®: { "notes": [ { "title": "...", "content": "..." } ] } (JSONä¸­çš„titleä¹Ÿå¿…é¡»<=20å­—)

ç¯‡æ•° ${count}ã€‚` }]
  };

  // Process files to be actual content parts (Inline Data or Text)
  const fileParts = await Promise.all(files.map(f => prepareFilePart(f)));
  
  const contents = [{ 
      role: 'user', 
      parts: [
          { text: context }, 
          ...fileParts
      ] 
  }];

  try {
    const response = await fetchGemini('streamGenerateContent?alt=sse', {
      contents,
      systemInstruction,
      generationConfig: { 
          temperature: fidelity === FidelityMode.STRICT ? 0.2 : 0.9, 
      }
    }, true);

    if (!response.body) throw new Error("No response body");

    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    
    let fullText = "";
    let thoughtBuffer = "";
    let dialogueBuffer = "";
    let inThought = false;
    let dataMarkerFound = false;

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      const chunkStr = decoder.decode(value, { stream: true });
      const lines = chunkStr.split('\n');
      
      for (const line of lines) {
        let content = "";
        const trimmed = line.trim();
        
        if (trimmed.startsWith('data:')) {
            const jsonStr = trimmed.slice(5).trim();
            if (jsonStr === '[DONE]') continue;
            try {
                const data = JSON.parse(jsonStr);
                content = data.candidates?.[0]?.content?.parts?.[0]?.text || 
                          data.choices?.[0]?.delta?.content || "";
            } catch (e) {}
        } 

        if (content) {
            fullText += content;

            if (dataMarkerFound) continue; 

            if (!inThought && content.includes(THOUGHT_START)) {
                inThought = true;
            }
            
            if (inThought) {
                thoughtBuffer += content;
                if (thoughtBuffer.includes(THOUGHT_END)) {
                    inThought = false;
                    const rawThought = thoughtBuffer.replace(THOUGHT_START, '').replace(THOUGHT_END, '');
                    if (onToken) onToken(dialogueBuffer, rawThought);
                } else {
                    if (onToken) onToken(dialogueBuffer, thoughtBuffer.replace(THOUGHT_START, ''));
                }
            } else {
                if (fullText.includes(DATA_MARKER)) {
                    dataMarkerFound = true;
                    const parts = fullText.split(DATA_MARKER);
                    dialogueBuffer = parts[0].replace(/\[\[THOUGHT\]\][\s\S]*?\[\[\/THOUGHT\]\]/g, '').trim();
                } else {
                    dialogueBuffer += content;
                }
                
                if (!inThought && onToken) {
                     onToken(dialogueBuffer, thoughtBuffer.replace(THOUGHT_START, '').replace(THOUGHT_END, ''));
                }
            }
        }
      }
    }

    let finalThought = "";
    let finalDialogue = fullText;
    let jsonPart = null;

    const tStart = fullText.indexOf(THOUGHT_START);
    const tEnd = fullText.indexOf(THOUGHT_END);
    if (tStart !== -1 && tEnd !== -1) {
        finalThought = fullText.substring(tStart + THOUGHT_START.length, tEnd).trim();
        finalDialogue = fullText.substring(0, tStart) + fullText.substring(tEnd + THOUGHT_END.length);
    }

    const splitParts = finalDialogue.split(DATA_MARKER);
    finalDialogue = splitParts[0].trim();
    if (splitParts.length > 1) {
        jsonPart = splitParts[1].trim();
    }

    let parsedNotes: BulkNote[] = [];
    if (jsonPart) {
        try { 
            const parsed = extractAndParseJSON(jsonPart); 
            parsedNotes = parsed?.notes || [];
        } catch (e) { console.error("Stream JSON Error", e); }
    }

    return {
      dialogueText: finalDialogue,
      thought: finalThought,
      notes: parsedNotes
    };

  } catch (error: any) {
    throw new Error(`ç”Ÿæˆä¸­æ–­: ${error.message}`);
  }
};

export const streamPersonaAnalysis = async (
    samples: string,
    onToken: (text: string) => void
): Promise<PersonaAnalysis> => {
    try {
        const response = await fetchGemini('streamGenerateContent?alt=sse', {
            contents: [{ role: 'user', parts: [{ text: `ä»¥ä¸‹æ˜¯æˆ‘çš„æ ·æœ¬ï¼Œè¯·åˆ†æé£æ ¼å¹¶è¿”å› JSONï¼š\n\n${samples}` }] }],
            systemInstruction: { parts: [{ text: ANALYSIS_SYSTEM_PROMPT + "\n\nIMPORTANT: Return ONLY valid JSON. The 'tone' field MUST be concise (max 8 characters). No Markdown." }] },
            generationConfig: { temperature: 0.4, maxOutputTokens: 8192, responseMimeType: "application/json" }
        }, true);

        if (!response.body) throw new Error("No response body");
        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let fullText = "";

        while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            const chunk = decoder.decode(value, { stream: true });
            const lines = chunk.split('\n');
            for(const line of lines) {
                if(line.startsWith('data:') && line !== 'data: [DONE]') {
                    try {
                        const data = JSON.parse(line.slice(5));
                        const text = data.candidates?.[0]?.content?.parts?.[0]?.text || data.choices?.[0]?.delta?.content;
                        if(text) { fullText += text; onToken(fullText); }
                    } catch(e){}
                }
            }
        }
        
        const result = extractAndParseJSON(fullText);
        
        if (result && result.tone) {
            return result;
        } else {
            return { 
                tone: "è‡ªå®šä¹‰é£æ ¼ (è‡ªåŠ¨æå–)", 
                keywords: ["æå–ç»“æœ"], 
                emojiDensity: "æœªè¯†åˆ«", 
                structure: "æœªè¯†åˆ«", 
                writerPersonaPrompt: fullText.substring(0, 1000)
            };
        }
    } catch (e: any) {
        throw new Error(`åˆ†æå¤±è´¥: ${e.message}`);
    }
};

export const testConnection = async (): Promise<{ success: boolean; message: string }> => {
    try {
        await fetchGemini('generateContent', {
            contents: [{ role: 'user', parts: [{ text: 'Ping' }] }],
            generationConfig: { maxOutputTokens: 1 }
        });
        return { success: true, message: "è¿æ¥æˆåŠŸ" };
    } catch (e: any) {
        return { success: false, message: e.message || "è¿æ¥å¤±è´¥" };
    }
};
